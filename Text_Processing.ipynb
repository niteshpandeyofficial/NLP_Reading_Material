{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRQ4dPKw7rVs",
        "outputId": "fa8e67f2-4c42-4887-9462-77c402e1f1e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi I # am nitesh', 'I stay in 999! Mumbai', 'My age is 32']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "text='Hi I # am nitesh,I stay in 999! Mumbai,My age is 32'\n",
        "\n",
        "text.split(',')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "re.findall('[\\w]+',text)"
      ],
      "metadata": {
        "id": "wcpVYrM073vb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d4d42e-cd8a-4b9c-dbc4-16dc4ccac302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi',\n",
              " 'I',\n",
              " 'am',\n",
              " 'nitesh',\n",
              " 'I',\n",
              " 'stay',\n",
              " 'in',\n",
              " '999',\n",
              " 'Mumbai',\n",
              " 'My',\n",
              " 'age',\n",
              " 'is',\n",
              " '32']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token=re.compile('[.?]').split(text)\n",
        "print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eESDZCDcZC-9",
        "outputId": "40e15adf-85ce-430f-cad5-9951d69bf6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi I # am nitesh,I stay in 999! Mumbai,My age is 32']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIAx5JrqZVRk",
        "outputId": "d7f362dc-a983-4930-83f0-247535630dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "94hFTh_cZiw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var=\"\"\"\n",
        "You're serializing a large file and passing it as an argument to the function.\n",
        "I assume you're using EC2. So you could instead store the file to the AWS EC2's\n",
        "instance storage or EBS first\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6JPojiTcZrlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trB--zV4aHPY",
        "outputId": "d69b1032-e899-4b39-d54a-6e8287ec149b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgLjDtOTaBUO",
        "outputId": "7e81a7ab-5344-4da7-c58a-e58284c5a390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['You',\n",
              " \"'re\",\n",
              " 'serializing',\n",
              " 'a',\n",
              " 'large',\n",
              " 'file',\n",
              " 'and',\n",
              " 'passing',\n",
              " 'it',\n",
              " 'as',\n",
              " 'an',\n",
              " 'argument',\n",
              " 'to',\n",
              " 'the',\n",
              " 'function',\n",
              " '.',\n",
              " 'I',\n",
              " 'assume',\n",
              " 'you',\n",
              " \"'re\",\n",
              " 'using',\n",
              " 'EC2',\n",
              " '.',\n",
              " 'So',\n",
              " 'you',\n",
              " 'could',\n",
              " 'instead',\n",
              " 'store',\n",
              " 'the',\n",
              " 'file',\n",
              " 'to',\n",
              " 'the',\n",
              " 'AWS',\n",
              " 'EC2',\n",
              " \"'s\",\n",
              " 'instance',\n",
              " 'storage',\n",
              " 'or',\n",
              " 'EBS',\n",
              " 'first']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sent_tokenize(var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3hbVSi-aDub",
        "outputId": "1d14e9fa-7691-4ed7-d6aa-035facac7101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"\\nYou're serializing a large file and passing it as an argument to the function.\",\n",
              " \"I assume you're using EC2.\",\n",
              " \"So you could instead store the file to the AWS EC2's \\ninstance storage or EBS first\"]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize"
      ],
      "metadata": {
        "id": "S796esZHadeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordpunct_tokenize(var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMbWn7tgavu_",
        "outputId": "c06c70e8-4d26-48f9-b6ba-2aff14be6300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['You',\n",
              " \"'\",\n",
              " 're',\n",
              " 'serializing',\n",
              " 'a',\n",
              " 'large',\n",
              " 'file',\n",
              " 'and',\n",
              " 'passing',\n",
              " 'it',\n",
              " 'as',\n",
              " 'an',\n",
              " 'argument',\n",
              " 'to',\n",
              " 'the',\n",
              " 'function',\n",
              " '.',\n",
              " 'I',\n",
              " 'assume',\n",
              " 'you',\n",
              " \"'\",\n",
              " 're',\n",
              " 'using',\n",
              " 'EC2',\n",
              " '.',\n",
              " 'So',\n",
              " 'you',\n",
              " 'could',\n",
              " 'instead',\n",
              " 'store',\n",
              " 'the',\n",
              " 'file',\n",
              " 'to',\n",
              " 'the',\n",
              " 'AWS',\n",
              " 'EC2',\n",
              " \"'\",\n",
              " 's',\n",
              " 'instance',\n",
              " 'storage',\n",
              " 'or',\n",
              " 'EBS',\n",
              " 'first']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer"
      ],
      "metadata": {
        "id": "ZVMr7Vwyaxet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import spacy Library"
      ],
      "metadata": {
        "id": "Vkj46ok2Yoek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "WM3nOHw4qQ8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FrIK8-ZYyQY",
        "outputId": "cdc94a68-03ad-47d2-91c3-5661e15da059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m‚ö† As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English"
      ],
      "metadata": {
        "id": "Gq1XHrpZZAiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=English()\n",
        "text=\"You're serializing a large file and passing it as an argument to the function. I assume you're using EC2.\"\n",
        "doc=nlp(text)\n",
        "token_list=[]\n",
        "\n",
        "for tokens in doc:\n",
        "  token_list.append(tokens.text)\n",
        "print(token_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q2h0BpyZSYJ",
        "outputId": "1d8f9f23-65ff-43f9-b672-ca2b4e884fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['You', \"'re\", 'serializing', 'a', 'large', 'file', 'and', 'passing', 'it', 'as', 'an', 'argument', 'to', 'the', 'function', '.', 'I', 'assume', 'you', \"'re\", 'using', 'EC2', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### It's produce same result as above"
      ],
      "metadata": {
        "id": "DOEc8cYJcGkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "text=\"You're serializing a large file and passing it as an argument to the function. I assume you're using EC2.\"\n",
        "doc=nlp(text)\n",
        "\n",
        "for tokens in doc:\n",
        "  token_list.append(tokens.text)\n",
        "print(token_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJe1mlbwaE2J",
        "outputId": "4dafd7ba-4eea-40b5-f33f-d540e120a16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['You', \"'re\", 'serializing', 'a', 'large', 'file', 'and', 'passing', 'it', 'as', 'an', 'argument', 'to', 'the', 'function', '.', 'I', 'assume', 'you', \"'re\", 'using', 'EC2', '.', 'You', \"'re\", 'serializing', 'a', 'large', 'file', 'and', 'passing', 'it', 'as', 'an', 'argument', 'to', 'the', 'function', '.', 'I', 'assume', 'you', \"'re\", 'using', 'EC2', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convert to sentence"
      ],
      "metadata": {
        "id": "vOWnEcNId4-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=English()\n",
        "nlp.add_pipe('sentencizer')\n",
        "text1=\"You're serializing a large file and passing it as an argument to the function. I assume you're using EC2.\"\n",
        "docs=nlp(text1)\n",
        "sent_list=[]\n",
        "for token in docs.sents:\n",
        "  print(token.text)\n",
        "\n",
        "#print(sent_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJFzTnPPb8go",
        "outputId": "8ef7d3e1-768f-44b9-fe45-72b0f271bf8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You're serializing a large file and passing it as an argument to the function.\n",
            "I assume you're using EC2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Read the file and fetch the sentences from it"
      ],
      "metadata": {
        "id": "qCOkPJHbhTp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/test_data_nltk.txt','r') as f:\n",
        "  val=f.read()\n",
        "  doc=nlp(val)\n",
        "  for token in doc.sents:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghcu8pyWc7oP",
        "outputId": "82a0bb4d-c4eb-4183-aa67-af70f70f92ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intel i5 ka koi bhi generation.\n",
            "\n",
            "RAM-8 gb but expandable ho.system type-64bit.\n",
            "\n",
            "preinstalled window -11.SSD-512GB.Core-4 and above.thread -4 and above.\n",
            "\n",
            "base speed -1.90 ghz and aboveGraphic card -inbuild bhi chal jayega.\n",
            "\n",
            "laptop size-14 inch preferable.\n",
            "\n",
            "https://engage.peroptyx.ai/#/user/dashboard.\n",
            "\n",
            "https://www.youtube.com/watch?v=Nll4pKmJBO0.\n",
            "\n",
            "üòÑ ,üòÅ.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Read the file and fetch the word from it"
      ],
      "metadata": {
        "id": "F6ljxyOBhZgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/test_data_nltk.txt','r') as f:\n",
        "  val=f.read()\n",
        "  doc=nlp(val)\n",
        "  for token in doc:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isrF7rbcgUn2",
        "outputId": "96aec661-c372-40fe-984b-c1d16a9157a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intel\n",
            "i5\n",
            "ka\n",
            "koi\n",
            "bhi\n",
            "generation\n",
            ".\n",
            "\n",
            "\n",
            "RAM-8\n",
            "gb\n",
            "but\n",
            "expandable\n",
            "ho.system\n",
            "type-64bit\n",
            ".\n",
            "\n",
            "\n",
            "preinstalled\n",
            "window\n",
            "-11.SSD-512GB.Core-4\n",
            "and\n",
            "above.thread\n",
            "-4\n",
            "and\n",
            "above\n",
            ".\n",
            "\n",
            "\n",
            "base\n",
            "speed\n",
            "-1.90\n",
            "ghz\n",
            "and\n",
            "aboveGraphic\n",
            "card\n",
            "-inbuild\n",
            "bhi\n",
            "chal\n",
            "jayega\n",
            ".\n",
            "\n",
            "\n",
            "laptop\n",
            "size-14\n",
            "inch\n",
            "preferable\n",
            ".\n",
            "\n",
            "\n",
            "https://engage.peroptyx.ai/#/user/dashboard\n",
            ".\n",
            "\n",
            "\n",
            "https://www.youtube.com/watch?v=Nll4pKmJBO0\n",
            ".\n",
            "\n",
            "\n",
            "üòÑ\n",
            ",\n",
            "üòÅ\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"Tokenization is the process of splitting text into tokens. It's an important step in NLP.\"\n",
        "\n",
        "# Tokenization using regex\n",
        "tokens = re.findall(r'\\w+|\\S', text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7FbMm-VhNRx",
        "outputId": "02fb8992-defd-489f-e1cb-953078b8fdbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tokenization', 'is', 'the', 'process', 'of', 'splitting', 'text', 'into', 'tokens', '.', 'It', \"'\", 's', 'an', 'important', 'step', 'in', 'NLP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"Tokenization is the process of splitting text into tokens. It's an important step in NLP.\"\n",
        "tokens = re.findall(r'\\w+|\\S', text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "0xWMqHVXxHqy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}